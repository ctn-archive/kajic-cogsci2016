# Towards a Cognitively Realistic Representation of Word Associations

[Associated data files can be found on figshare.](https://dx.doi.org/10.6084/m9.figshare.2066799)

## Reproducing plots and figures

### Requirements

Most of the requirements should be installable with `pip`.

* [Python 2.7](https://www.python.org/) (Python 3 might work, but is untested)
* [NumPy](http://www.numpy.org/)
* [SciPy](http://www.scipy.org/)
* [matplotlib](http://matplotlib.org/)
* [pandas](http://pandas.pydata.org/)
* [Seaborn](http://stanford.edu/~mwaskom/software/seaborn/)
* [statsmodels](http://statsmodels.sourceforge.net/)
* [xlrd](http://www.python-excel.org/)
* [doit](http://pydoit.org/)

#### For running the spiking neural network model

* [Nengo](https://github.com/nengo/nengo) [2.0.3](https://github.com/nengo/nengo/releases/tag/v2.0.3)
* [ctn_benchmarks](https://github.com/ctn-waterloo/ctn_benchmarks) [1aa6e93](https://github.com/ctn-waterloo/ctn_benchmarks/tree/1aa6e93b912fd16170ba8e3426f8718c85070504)

To do the batch run to get the accuracy data for Figure 5:

* [psyrun](https://github.com/jgosmann/psyrun) [41f6c20](https://github.com/jgosmann/psyrun/tree/41f6c203b65c14e7dc5c1ef424c75ec3ca8f9dbb)

#### For processing the raw Google n-gram data

* [joblib](https://pythonhosted.org/joblib/)

Normally preprocessed n-gram data will be fetched from figshare and this
dependency is not required. It is only needed to regenerate the data published
on figshare.


### Fetching and processing data

Run `doit` to fetch and process most of the required data.

To obtain the data for the spiking neural network plotted in Figure 4 run
`python sparat/model/benchmark.py`. Note that this requires up to 6GB of memory.

To obtain the data for the accuracy of the spiking neural network plotted in
Figure 5 run `psy-doit`. Note that this requires up to 6GB of memory and can
take a long time. This will produce `psywork/result.h5`. Copy or move this file
to `data/neural-accuracy.h5`.


### Creating tables and plots

After you performed the previous step to generate the required data, you find
Jupyter notebooks in `notebooks`. Run these to recreate the plots and tables in
the paper.


## Repository organization

### data
Data files not included in the directory and are either downloaded from
external resources or generated by scripts.

### figures
Figures used in the paper.

### notebooks
Jupyter notebooks with data analyses and plotting.

### psy-tasks
Task definition files for the serial farming tool `psyrun`.

### scripts
Data processing scripts meant to be invoked from the command line.

### sparat
Python source code for processing the data and the model excluding command line
tools.

### tables
Generated LaTeX tables for the paper.

### txt
Documentation including the CogSci paper.
